---
title: "Projet_Velib"
output:
  pdf_document: default
  html_document: default
date: "2024-02-16"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
library(ggplot2)
library(reshape)
library(reshape2)
library(gridExtra)
library(factoextra)
library(FactoMineR)
library(tidyverse)
library(cluster)

library(boot)
library(nortest)
library(corrplot)
library(ggmap)

library(caret)
library(clue)

library(NbClust)
library(mclust)
```


```{r}
load("velib.RData")
summary(velib)
```


#Préparation des données

```{r}
loading = as.matrix(velib$data)
colnames(loading) = 1:ncol(loading)
rownames(loading) = velib$names
#coord = read.csv("velibCoord.csv")
#coord = as.matrix(coord)

stations = 1:nrow(loading)
coord = velib$position[stations,]
coord$bonus = velib$bonus[stations] # 1 = sur une colline, 0 = non

dates = 14:181
loading=loading[stations, dates]
head(loading)
head(coord)
```

```{r}
intervals = unname(c(summary(rowMeans(loading))[2:5],0.7,1.1))
intervals
```

```{r}

labels_cat = c("très peu chargé","peu chargé","moyen", "chargé", "très chargé")

# Créer un nouveau DataFrame pour les données catégoriques
categorical_data <- data.frame(matrix(ncol = ncol(loading), nrow = nrow(loading)))
colnames(categorical_data) <- colnames(loading)

# Appliquer la transformation
for (column in colnames(loading)) {
  categorical_data[,column] <- cut(loading[,column], breaks = intervals, labels = labels_cat, right = FALSE)
}

categorical_data = replace(categorical_data, is.na(categorical_data), "très peu chargé")

# Afficher les premières lignes du nouveau DataFrame
head(categorical_data)


```


# Décomposition des données en jours

```{r}
loading =as.data.frame(loading)

RemplissageMoyenStation = rowMeans(loading)
#RemplissageMoyenStationSort = sort(RemplissageMoyenStation, decreasing = TRUE)
#plot(RemplissageMoyenStationSort)

RemplissageMoyenHeure = colMeans(loading)


lundi = loading[,c(0:24)]
mardi = loading[,c(25:48)]
mercredi = loading[,c(49:72)]
jeudi = loading[,c(73:96)]
vendredi = loading[,c(97:120)]
samedi = loading[,c(121:144)]
dimanche = loading[,c(145:168)]

lundiMoyHeure = RemplissageMoyenHeure[c(0:24)]
mardiMoyHeure = RemplissageMoyenHeure[c(25:48)]
mercrediMoyHeure = RemplissageMoyenHeure[c(49:72)]
jeudiMoyHeure = RemplissageMoyenHeure[c(73:96)]
vendrediMoyHeure = RemplissageMoyenHeure[c(97:120)]
samediMoyHeure = RemplissageMoyenHeure[c(121:144)]
dimancheMoyHeure = RemplissageMoyenHeure[c(145:168)]


lundiMoy = rowMeans(loading[, c(1:24)])
mardiMoy = rowMeans(loading[, c(25:48)])
mercrediMoy = rowMeans(loading[, c(49:72)])
jeudiMoy = rowMeans(loading[, c(73:96)])
vendrediMoy = rowMeans(loading[, c(97:120)])
samediMoy = rowMeans(loading[, c(121:144)])
dimancheMoy = rowMeans(loading[, c(145:168)])

lundiRepos = as.data.frame(c(lundi[0:7],lundi[20:24]))
lundiTravail = as.data.frame(c(lundi[8:19]))

mardiRepos = as.data.frame(c(mardi[0:7],mardi[20:24]))
mardiTravail = as.data.frame(c(mardi[8:19]))

mercrediRepos = as.data.frame(c(mercredi[0:7],mercredi[20:24]))
mercrediTravail = as.data.frame(c(mercredi[8:19]))

jeudiRepos = as.data.frame(c(jeudi[0:7],jeudi[20:24]))
jeudiTravail = as.data.frame(c(jeudi[8:19]))

vendrediRepos = as.data.frame(c(vendredi[0:7],vendredi[20:24]))
vendrediTravail = as.data.frame(c(vendredi[8:19]))

samediRepos = as.data.frame(c(samedi[0:7],samedi[20:24]))
samediTravail = as.data.frame(c(samedi[8:19]))

dimancheRepos = as.data.frame(c(dimanche[0:7],dimanche[20:24]))
dimancheTravail = as.data.frame(c(dimanche[8:19]))


jours = cbind(lundi,mardi,mercredi,jeudi,vendredi,samedi,dimanche)
joursMoy = cbind(lundiMoy,mardiMoy,mercrediMoy,jeudiMoy,vendrediMoy,samediMoy,dimancheMoy)

joursTravail = cbind(lundiTravail,mardiTravail,mercrediTravail,jeudiTravail,vendrediTravail,samediTravail,dimancheTravail)
joursRepos = cbind(lundiRepos,mardiRepos,mercrediRepos,jeudiRepos,vendrediRepos,samediRepos,dimancheRepos)

joursTravailMoy = cbind(rowMeans(lundiTravail),rowMeans(mardiTravail),rowMeans(mercrediTravail),rowMeans(jeudiTravail),rowMeans(vendrediTravail),rowMeans(samediTravail),rowMeans(dimancheTravail))
joursReposMoy = cbind(rowMeans(lundiRepos),rowMeans(mardiRepos),rowMeans(mercrediRepos),rowMeans(jeudiRepos),rowMeans(vendrediRepos),rowMeans(samediRepos),rowMeans(dimancheRepos))

colnames(joursReposMoy) = c("LundiRepos","MardiRepos", "MercrediRepos","JeudiRepos","VendrediRepos","SamediRepos","DimancheRepos")
colnames(joursTravailMoy) = c("LundiTravail","MardiTravail", "MercrediTravail","JeudiTravail","VendrediTravail","SamediTravail","DimancheTravail")

#corrplot(cor(jours),method="ellipse")
```

```{r}
# Créer un nouveau DataFrame pour les données catégoriques
load_quali = data.frame(matrix(ncol = ncol(joursTravailMoy)*2, nrow = nrow(joursTravailMoy)))
#load_quali = rbind(joursTravailMoy,joursReposMoy)
colnames(load_quali) <- c(colnames(joursTravailMoy),colnames(joursReposMoy))

# Appliquer la transformation
for (column in colnames(joursTravailMoy)) {
  load_quali[,column] <- cut(joursTravailMoy[,column], breaks = intervals, labels = labels_cat, right = FALSE)
}
for (column in colnames(joursReposMoy)) {
  load_quali[,column] <- cut(joursReposMoy[,column], breaks = intervals, labels = labels_cat, right = FALSE)
}

load_quali = replace(load_quali, is.na(load_quali), "très peu chargé")
load_quali = cbind(load_quali, coord$bonus)


names(load_quali)[names(load_quali) == "coord$bonus"] <- "bonus"

load_quali$bonus[load_quali$bonus == 1] <- "colline"
load_quali$bonus[load_quali$bonus == 0] <- "plaine"

# Afficher les premières lignes du nouveau DataFrame
head(load_quali)
head(joursTravailMoy)
head(joursReposMoy)

```




# Vérification des données

### Données manquantes
```{r}
sum(is.na(loading))
sum(is.na(coord))
```

### Données dupliquées

```{r}
sum(duplicated(loading))
```

# Etude du remplissage des stations selon l'heure ou le jour

```{r}
days = c(0,24,48,72,96,120,144,168)
i = 5

plot(c(1:168),loading[i,],type="l",main = paste("Evolution de la disponibilité à la station",rownames(loading)[i]),cex=0.1)
abline(v = days, col="red")
abline(v = days+12, col="darkgreen",lty=2)

```

```{r}

i_array = sample(1:1000,9)

par(mfrow=c(3,3))
for (i in 1:9) {
    plot(c(1:168),loading[i_array[i],],type="l" ,xlab = row.names(loading[i,]))
    abline(v = days, col="red")
} 
```
```{r}
plot(RemplissageMoyenHeure,type='l', main = "Remplissage moyen par heure")
abline(v = days, col="red")
abline(v = days+12, col="darkgreen",lty=2)
abline(h = mean(RemplissageMoyenHeure), col = 'blue')
plot(rowMeans(loading), type='l', main = "Remplissage moyen par station")
abline(h = mean(RemplissageMoyenHeure), col = 'blue')
```


```{r, fig.width = 15, fig.height=15}

listPlot = list()
h = 18
hours = 24*c(0:6) + h
nomJours = c("Lundi","Mardi","Mercredi","Jeudi","Vendredi","Samedi","Dimanche")

dfi = coord

for (i in 1:7){
  
  dfi$loading = loading[,hours[i]]
  listPlot[[i]] = ggplot(dfi, aes(x = longitude, y = latitude, color = loading)) + geom_point() + ggtitle(paste("Chargement des stations ",nomJours[i], "à",h,"heures."))
}

do.call(grid.arrange,c(listPlot,ncol=2))

```

```{r, fig.width = 15, fig.height=15}
# Le lundi, à différentes heures

hours = c(1, 6, 12, 18, 22)
listPlot = list()
dfi = coord

for (i in 1:5){
  dfi$loading = loading[,hours[i]]
  
  listPlot[[i]] = ggplot(dfi, aes(x = longitude, y = latitude, color = loading)) + geom_point() + ggtitle(paste("Chargement des stations lundi à",hours[i],"heures."))
}

do.call(grid.arrange,c(listPlot,ncol=2))

```

```{r}
#Chargement moyen à 18h

h = 18

hours = 24*c(0:6) + h

loading18h = loading[hours]
head(loading18h)

dfi = coord
dfi$loading = rowMeans(loading18h)

ggplot(dfi, aes(x = longitude, y = latitude, color = loading)) + geom_point() + ggtitle(paste("Chargement Moyen à",h,"heures"))

```

# Etude de l'altitude des stations du jeu de données

```{r}
pie(c(sum(coord$bonus == 1), sum(coord$bonus == 0)), label = c("Stations en altitude","Stations en plaine"))
```


```{r}
dfi = coord
ggplot(dfi, aes(x = longitude, y = latitude, color = bonus)) + geom_point() + ggtitle("Stations en altitude")
```

# Analyse en ACP

```{r}

data_scale = scale(loading)
pca = PCA(data_scale,ncp = 5,graph=FALSE)

data_pca = pca$ind$coord

grid.arrange(
    fviz_eig(pca), 
    fviz_pca_var(pca,axes=c(1,2),label=""),
    fviz_pca_var(pca,axes=c(2,3),label=""),
    ncol=3
)


print(pca$eig[1:10,])
```
```{r}
plot(pca$eig[,2], type = 'l', main = "Variance expliquée par composantes")
plot(pca$eig[1:10,2], type = 'l', main = "Variance expliquée par les 10 premières composantes")


plot(pca$var$coord[,2],type='l',col='blue', main = "Première et deuxième composante principale")
lines(pca$var$coord[,1],type='l',col='red')


fviz_pca_ind(pca, label ="" , title= "Graphe des individus suivant les composantes 1 & 2")
fviz_pca_ind(pca, axes = c(1,3), label ="" , title= "Graphe des individus suivant les composantes 1 & 3")

hab <- ifelse(RemplissageMoyenStation <= 0.4, 'faible',
              ifelse(RemplissageMoyenStation <= 0.6, 'moyen', 'élevé'))
fviz_pca_ind(pca,label="",habillage = as.factor(hab), title = "Graphes des individus colorés suivant le remplissage moyen")


```

```{r}
corrplot(cor(joursMoy), method="ellipse")
```

```{r}
joursScale = scale(joursMoy)
pcaJours = PCA(joursScale,ncp = 5,graph=FALSE)

summary(pcaJours)
```
```{r}
plot(pcaJours$eig[1:5,2], type='l')

fviz_pca_ind(pcaJours, label ="" , title= "Graphe des individus suivant les composantes 1 & 2")
fviz_pca_ind(pcaJours, axes = c(1,3), label ="" , title= "Graphe des individus suivant les composantes 1 & 3")

```

```{r}
grid.arrange(
    fviz_eig(pcaJours), 
    fviz_pca_var(pcaJours,axes=c(1,2)),
    fviz_pca_var(pcaJours,axes=c(2,3)),
    ncol=3
)


```






```{r}
corrplot(cor(joursTravailMoy),method="ellipse")
corrplot(cor(joursReposMoy),method="ellipse")
corrplot(cor(cbind(joursTravailMoy,joursReposMoy)),method="ellipse")
```


```{r}
library(leaflet)
library(dplyr)

# Set your Stadia Maps API key
apikey <- "bdfc537c-e86b-4abb-8c63-4cedfa75cadd"

j <- 0
h <- 6
jours_data <- loading[, j*24 + h] 
pal <- colorNumeric(palette = "inferno", domain = jours_data)

# Create a leaflet map
map <- leaflet(data = coord) %>%
  addProviderTiles(provider = leaflet::providers$Stadia.AlidadeSmooth, 
                   options = providerTileOptions(apikey = apikey)) %>%
  addCircles(lng = ~longitude, lat = ~latitude, color = ~pal(jours_data), 
             fillOpacity = 0.8, radius = 40) %>%
  addLegend( pal = pal, values = jours_data,
            title = paste("Remplissage jour", j, "à", h, "h"),
            opacity = 1)
map

```

# ACP




```{r}
joursTR_Moy = cbind(joursTravailMoy,joursReposMoy)

joursTR_scale = scale(joursTR_Moy)
pcaJoursTR = PCA(joursTR_scale,ncp = 5,graph=FALSE)

grid.arrange(
    fviz_eig(pcaJoursTR), 
    fviz_pca_var(pcaJoursTR,axes=c(1,2)),
    ncol=2
)

fviz_pca_var(pcaJoursTR,axes=c(1,3))


print(pcaJoursTR$eig)
```

```{r}
plot(pcaJoursTR$eig[1:5,2], type='l')

fviz_pca_ind(pcaJoursTR ,label = "", title= "Graphe des individus suivant les composantes 1 & 2")
fviz_pca_ind(pcaJoursTR, axes = c(1,3) ,label = "", title= "Graphe des individus suivant les composantes 1 & 3")

plot(pcaJoursTR$var$coord[,1],type='l',col='blue', main = "Première composante principale")
plot(pcaJoursTR$var$coord[,2],type='l',col='red', main = "Deuxième composante principale")
```

# MCA

```{r}
res.mca = MCA(load_quali, graph = FALSE)
summary(res.mca)
```

```{r}
fviz_screeplot(res.mca)
```



```{r}
# fviz_mca_var(res.mca, choice="var")
# fviz_mca_biplot(res.mca, repel=FALSE, ggtheme = theme_minimal(),label="")
```

```{r}
# library(ade4)
# 
# load_quali$bonus = as.factor(load_quali$bonus)
# acm = dudi.acm(load_quali, scannf = FALSE, nf = 5)
# 
# couleurs <- rep("blue", length(acm$li))  # Initialisez toutes les couleurs avec "blue"
# 
# # Définissez les couleurs spécifiques pour les points que vous souhaitez changer
# couleurs[1] <- "red"  # Par exemple, les points 1, 3 et 5 seront en rouge
# 
# # Affichez la visualisation en spécifiant les couleurs
# fviz_mca_var(acm,, repel=TRUE, labelsize = 2)


```

```{r}
# couleurs_bonus <- ifelse(load_quali$bonus == "colline", "blue", "red")  # Définir les couleurs en fonction des modalités
# 
# # Visualiser les colonnes de l'ACM en fonction de la variable bonus
# fviz_ca_col(acm$li)#, col.col = couleurs_bonus)
# fviz_mca_biplot(acm$li, col.var = couleurs_bonus)
```


```{r}
# # Initialiser une liste pour stocker les tables de contingence
# contingency_tables <- list()
# 
# # Itérer à travers chaque colonne du dataframe
# for (col in names(load_quali)) {
#   # Créer une table de contingence pour la colonne actuelle
#   contingency_table <- table(load_quali[[col]])
#   
#   # Stocker la table de contingence dans la liste
#   contingency_tables[[col]] <- contingency_table
# }
# 
# # Afficher les tables de contingence
# for (i in seq_along(contingency_tables)) {
#   cat("Table de contingence pour la colonne", names(load_quali)[i], ":\n")
#   print(contingency_tables[[i]])
#   cat("\n")
# }
# 
# table(contingency_tables)
# ```


# K-means, silhouette et dendogramme


#### Nombre de cluster idéal :


```{r}
fviz_nbclust(data_pca,method = 'wss', FUNcluster = kmeans)
```

```{r}
fviz_nbclust(data_pca,method = 'silhouette', FUNcluster = kmeans)
```
Avec une autre fonction :
```{r}
NbClust(data_pca, method = 'kmeans', index = 'all', max.nc = 10)$Best.nc
```




```{r}
d = dist(data_pca)
reskmeans3 = kmeans(data_pca,centers = 3)
fviz_cluster(reskmeans3,data = data_pca,labelsize=0,ellipse.type = "norm", axes=c(1,2))

sil = silhouette(reskmeans3$cluster, d)

fviz_silhouette(sil)

clusters_k3 = reskmeans3$cluster
```







```{r}
for (k in 2:10){
  km.res = kmeans(data_pca, centers = k, nstart = 25)
  
  sil = silhouette(km.res$cluster, dist(data_pca))
  plot(sil, main = paste("Sihouette",k), col = rainbow(length(unique(km.res$cluster))), border = NA)
  
  abline(v = mean(sil[,3]))
}


```




```{r}

# Set your Stadia Maps API key
apikey <- "bdfc537c-e86b-4abb-8c63-4cedfa75cadd"

register_stadiamaps(apikey, write = TRUE)

#bbox <- c(left = 24.61, bottom = 59.37, right = 24.94, top = 59.5)
#get_stadiamap(bbox, zoom = 12, maptype = "stamen_toner_lite") %>% ggmap()

qmplot(longitude, latitude,data = coord, maptype = "stamen_toner_lite",color=clusters_k3,) +
    labs(title = paste("Clusters")) + scale_color_gradient(low = "blue", high ="green")



profile1 = colMeans(loading[which(clusters_k3 == 1),])
profile2 = colMeans(loading[which(clusters_k3 == 2),])
profile3 = colMeans(loading[which(clusters_k3 == 3),])


min_value <- min(c(profile1, profile2, profile3))
max_value <- max(c(profile1, profile2, profile3))

plot(profile1, type = 'l', col = "blue", ylim = c(min_value, max_value))
lines(profile2,type='l', col = "grey")
lines(profile3,type='l', col = "green")
abline(v = days, col="red")
```

```{r}
library(leaflet)


num_clusters = 3

pal <- colorRampPalette(c("lightblue", "mediumblue"))(num_clusters)


colors <- colorFactor(palette = pal, domain = unique(clusters_k3))

map <- leaflet(coord) %>%
  addProviderTiles(provider = providers$Stadia.AlidadeSmooth, 
                   options = providerTileOptions(apikey = apikey)) %>%
  addCircles(lng = ~longitude, lat = ~latitude, color =  ~colors(clusters_k3),
             opacity = 1, fillOpacity = 0.8, radius = 50) %>%
  addLegend("bottomright", pal = colors, values = ~clusters_k3,
            title = "3 Clusters ",
            opacity = 1)

# Print the map
print(map)

```


## Avec 4 clusters :

```{r}
reskmeans4 = kmeans(data_pca,centers = 4)
fviz_cluster(reskmeans4,data = data_scale,labelsize=0,ellipse.type = "norm", axes=c(1,2))

sil = silhouette(reskmeans4$cluster,d)

fviz_silhouette(sil)

clusters_k4 = reskmeans4$cluster
```

```{r}

# Set your Stadia Maps API key
apikey <- "bdfc537c-e86b-4abb-8c63-4cedfa75cadd"

register_stadiamaps(apikey, write = TRUE)

#bbox <- c(left = 24.61, bottom = 59.37, right = 24.94, top = 59.5)
#get_stadiamap(bbox, zoom = 12, maptype = "stamen_toner_lite") %>% ggmap()

qmplot(longitude, latitude,data = coord, maptype = "stamen_toner_lite",color=clusters_k4,) +
    labs(title = paste("Clusters")) + scale_color_gradient(low = "blue", high ="green")



profile1 = colMeans(loading[which(clusters_k4 == 1),])
profile2 = colMeans(loading[which(clusters_k4 == 2),])
profile3 = colMeans(loading[which(clusters_k4 == 3),])
profile4 = colMeans(loading[which(clusters_k4 == 4),])


min_value <- min(c(profile1, profile2, profile3, profile4))
max_value <- max(c(profile1, profile2, profile3, profile4))

plot(profile1, type = 'l', col = "blue", ylim = c(min_value, max_value))
lines(profile2,type='l', col = "purple")
lines(profile3,type='l', col = "darkgreen")
lines(profile4,type='l', col = "green")
abline(v = days, col="red")
```
Globalement, les clusters 2 et 3 semblent avoir des comportements similaires en semaine.


```{r}

# Set your Stadia Maps API key
apikey <- "bdfc537c-e86b-4abb-8c63-4cedfa75cadd"

num_clusters = 4

pal <- colorRampPalette(c("lightblue", "mediumblue", "darkblue"))(num_clusters)


colors <- colorFactor(palette = pal, domain = unique(clusters_k4))

map <- leaflet(coord) %>%
  addProviderTiles(provider = providers$Stadia.AlidadeSmooth, 
                   options = providerTileOptions(apikey = apikey)) %>%
  addCircles(lng = ~longitude, lat = ~latitude, color =  ~colors(clusters_k4),
             opacity = 1, fillOpacity = 0.8, radius = 50) %>%
  addLegend("bottomright", pal = colors, values = ~clusters_k4,
            title = "Clusters",
            opacity = 1)

# Print the map
print(map)
```

Commentaire : Chaque cluster n'a pas une zone géographique propre, on constate néammoins plusieurs tendances se dessiner : Le cluster 1 est présent surtout au centre de Paris (ile de la Cité et alentours). Le cluster 4 correspond surtout aux arrondissement 15, 11, 12. Les clusters 3 et 2 semblent confondus.





## Clustering with Gaussian Mixture :

```{r}
gmm_model <- Mclust(data_pca,G=1:6)
summary(gmm_model)

print(paste("Nombre de clusters optimal",gmm_model$G))
```

```{r}
gmm_model$BIC

resBIC = Mclust(data_pca,G=2:30, modelNames = "VII")
summary(resBIC)
```


```{r}

 
# Get the cluster assignments
#cluster_assignments <- predict(gmm_model)$classification
 
# Visualize the results
#plot(loading, col = cluster_assignments, main = "GMM Clustering Results")
#points(gmm_model$parameters$mean, col = 1:3, pch = 8, cex = 2)

#fviz_mclust(gmm_model, labelsize = 0)
#fviz_cluster(gmm_clust,data = data_scale,labelsize=0,ellipse.type = "norm", axes=c(1,2))

ggplot(as.data.frame(data_pca), aes(x = pca$ind$coord[,1], y = pca$ind$coord[,2], color = as.factor(gmm_model$classification))) +
  geom_point() +
  scale_color_discrete(name = "Cluster") +
  labs(x = paste("Composante principale 1",substr(pca$eig[1],1,5),"%"), y = paste("Composante principale 2", substr(pca$eig[2],1,5),"%")) +
  theme_minimal()

clusters_gmm = gmm_model$classification
```


```{r}
# 
# profile1 = colMeans(loading[which(clusters_gmm == 1),])
# profile2 = colMeans(loading[which(clusters_gmm == 2),])
# profile3 = colMeans(loading[which(clusters_gmm == 3),])
# profile4 = colMeans(loading[which(clusters_gmm == 4),])
# profile5 = colMeans(loading[which(clusters_gmm == 5),])
# profile6 = colMeans(loading[which(clusters_gmm == 6),])
# 
# profiles_gmm = cbind(profile1,profile2,profile3,profile4, profile5,profile6)
# 
# corrplot(cor(profiles_gmm),method = "ellipse")
# 
# max(cor(profiles_gmm))
```



```{r}

#resICLall = Mclust(loading[!duplicated(rownames(data)), ], G=2:6)
#summary(resICLall)

#fviz_mclust(resICLall,data=data_pca,labelsize= 0)

# 
# resICLall = Mclust(data_pca)
# summary(resICLall)
# fviz_mclust(resICLall, data=data_pca, labelsize=0)
# 
# clusters_ICL = resICLall$classification
```

```{r}
gmm_model4 = Mclust(data_pca,G=4, modelNames = "VVE")
summary(gmm_model4)
clusters_gmm4 = gmm_model4$classification
```
```{r}
gmm_model_4_spherical = Mclust(data_pca, G=4, modelNames = "VII")
clusters_gmm4_spherical = gmm_model_4_spherical$classification
```




## Clustering with CAH
```{r}
d = dist(data_pca)

hclustsingle = hclust(d, method="single")
hclustcomplete = hclust(d, method="complete")
hclustaverage = hclust(d, method="average")
hclustward = hclust(d, method="ward.D")

# Dendograms visualization
#fviz_dend(hclustsingle)
#fviz_dend(hclustcomplete)
#fviz_dend(hclustaverage)
#fviz_dend(hclustward)
```


```{r}
nodePar <- list(lab.cex = 0.2, pch = c(NA, 19), 
                cex = 0.5, col = "red")

plot(as.dendrogram(hclustsingle), main = "Single Linkage", ylab = "Height", nodePar = nodePar, leaflab = "none",edgePar = list(col = 2:3, lwd = 2:1))

plot(as.dendrogram(hclustcomplete), main = "Complete Linkage",ylab = "Height", nodePar = nodePar, leaflab = "none",edgePar = list(col = 2:3, lwd = 2:1))

plot(as.dendrogram(hclustaverage), main = "Average Linkage", ylab = "Height", nodePar = nodePar, leaflab = "none",edgePar = list(col = 2:3, lwd = 2:1))

plot(as.dendrogram(hclustward), main = "Ward Linkage", ylab = "Height", nodePar = nodePar, leaflab = "none",edgePar = list(col = 2:3, lwd = 2:1),hang = -1)

``` 
On remarque que : 
1. **Single Linkage** : Forme des clusters en connectant les points les plus proches, souvent en longues chaînes, conduisant à un grand cluster progressivement ascendant.
2. **Complete Linkage** : Produit des clusters plus compacts et bien séparés en considérant la distance maximale entre les points, résultant en une structure équilibrée.
3. **Average Linkage** : Crée des clusters par la moyenne des distances entre tous les points, offrant une répartition équilibrée similaire à Complete Linkage.
4. **Ward Linkage** : Minimise la variance au sein des clusters, menant à des clusters distincts et homogènes, visibles par de grandes différences de hauteur dans le dendrogramme.

### Trouver le nombre de cluster optimal






```{r}
reshclust = cutree(hclustward, 4)

fviz_dend(hclustward, k=4, show_labels=FALSE, rect=TRUE)
```

Le dendrogramme représente une analyse de clustering hiérarchique via la méthode de Ward, divisant les données en trois clusters principaux (rouge, vert, bleu, violet). Le cluster rouge montre la plus grande similarité interne, le vert une similarité modérée, et le bleu la moindre, suggérant des niveaux de cohésion différents parmi les groupes. Ces clusters illustrent la segmentation efficace des données en fonction de leur homogénéité.


```{r}
clusters_cah = unname(reshclust)

ggplot(as.data.frame(data_pca), aes(x = pca$ind$coord[,1], y = pca$ind$coord[,2], color = as.factor(clusters_cah))) +
  geom_point() +
  scale_color_discrete(name = "Cluster") +
  labs(x = paste("Composante principale 1",substr(pca$eig[1],1,5),"%"), y = paste("Composante principale 2", substr(pca$eig[2],1,5),"%")) +
  theme_minimal()

```


Cette visualisation représente les résultats du clustering par la méthode de Ward appliquée à nos données transformées par une analyse en composantes principales (ACP). Quatres clusters distincts sont visibles, colorés en rouge, vert, violet et bleu, chacun regroupant des données avec des caractéristiques similaires. Les deux premières composantes principales, responsables de 66,88 % et 33,48 % de la variance. La répartition spatiale des points suggère que la segmentation par Ward a identifié des structures significatives au sein des données, facilitant ainsi l'interprétation et l'analyse ultérieure des groupes formés.


```{r}

# Set your Stadia Maps API key
apikey <- "bdfc537c-e86b-4abb-8c63-4cedfa75cadd"

register_stadiamaps(apikey, write = TRUE)

#bbox <- c(left = 24.61, bottom = 59.37, right = 24.94, top = 59.5)
#get_stadiamap(bbox, zoom = 12, maptype = "stamen_toner_lite") %>% ggmap()

qmplot(longitude, latitude,data = coord, maptype = "stamen_toner_lite",color=clusters_cah,) +
    labs(title = paste("Clusters")) + scale_color_gradient(low = "blue", high ="green")



profile1 = colMeans(loading[which(clusters_cah == 1),])
profile2 = colMeans(loading[which(clusters_cah == 2),])
profile3 = colMeans(loading[which(clusters_cah == 3),])


min_value <- min(c(profile1, profile2, profile3))
max_value <- max(c(profile1, profile2, profile3))

plot(profile1, type = 'l', col = "blue", ylim = c(min_value, max_value), xlab = "Heures", ylab = "Chargement moyen")
lines(profile2,type='l', col = "grey")
lines(profile3,type='l', col = "green")
abline(v = days, col="red")
```

Cette carte montre la répartition spatiale des clusters trouvés via la méthode de Ward sur les stations à Paris. Les points colorés en bleu, vert et gris représentent les clusters identifiés, avec des variations de concentration et de distribution dans les différents arrondissements de la ville.

Pour le graphe on répresente les tendances du chargement moyen des stations dans chaque cluster sur une semaine, avec des barres rouges délimitant chaque période de 24 heures. Les courbes colorées indiquent des variations distinctes de chargement pour chaque cluster : les stations en vertes ont un chargement élevé et constant, en gris présentent une utilisation modérée avec des pics matinaux et en soirée, tandis que les stations en bleu montrent une utilisation plus faible et fluctuante. Cela souligne les différences d'utilisation quotidienne entre les clusters.





## Map avec différentes méthodes de clusters :

```{r}

confusionMatrix(as.factor(clusters_k3), as.factor(clusters_cah))
confusionMatrix(as.factor(clusters_k3), as.factor(reshclust))
confusionMatrix(as.factor(clusters_k4), as.factor(clusters_gmm4))
```

On constate que les clusters trouvés avec les différentes classifications ne sont pas ordonnés de la même manière. ON propose alors un fonction pour les réordonner :

```{r}
clusterRearrange <- function(classif1, classif2) {
  
  confMatrix <- table(classif1, classif2)
  listMax <- apply(confMatrix, 2, which.max)
  
  confMatrix2 <- matrix(0, nrow = nrow(confMatrix), ncol = ncol(confMatrix))
  
  for (i in 1:length(listMax)) {
    confMatrix2[i, ] <- confMatrix[listMax[i], ]
  }
  
  classIndices <- numeric(length(classif2))
  
  for (i in 1:length(classif2)) {
    for (j in 1:nrow(confMatrix)) {
      if (classif2[i] == j) {
        classIndices[i] <- listMax[j]
        break
      }
    }
  }
  
  classif2_rearranged <- classif2

  for (i in 1:length(classif2)) {
    classif2_rearranged[i] = classIndices[i]
  }
  return(classif2_rearranged)
}

```

Cette fonction renvoie un vecteur identique au deuxième cluster passé en paramètres mais réarrangé suivant le premier.





```{r}
# 
reshclust_rearranged = clusterRearrange(clusters_k3, reshclust)
 
# confusionMatrix(as.factor(clusters_k3), as.factor(reshclust_rearranged))

clusters_gmm4_rearranged = clusterRearrange(clusters_k4, clusters_gmm4)

#confusionMatrix(as.factor(clusters_k4),as.factor(clusters_gmm4_rearranged))
```



```{r}

# Set your Stadia Maps API key
apikey <- "bdfc537c-e86b-4abb-8c63-4cedfa75cadd"

register_stadiamaps(apikey, write = TRUE)

#bbox <- c(left = 24.61, bottom = 59.37, right = 24.94, top = 59.5)
#get_stadiamap(bbox, zoom = 12, maptype = "stamen_toner_lite") %>% ggmap()

qmplot(longitude, latitude,data = coord, maptype = "stamen_toner_lite",color=clusters_k3,) +
    labs(title = paste("Clusters with k-means (3 clusters)")) + scale_color_gradient(name = "Clusters",low = "blue", high ="green")


qmplot(longitude, latitude,data = coord, maptype = "stamen_toner_lite",color=clusters_k4,) +
    labs(title = paste("Clusters with k-means (4 clusters)")) + scale_color_gradient(name = "Clusters",low = "blue", high ="green")


qmplot(longitude, latitude,data = coord, maptype = "stamen_toner_lite",color=clusters_cah,) +
    labs(title = paste("Clusters with CAH (3 clusters)")) + scale_color_gradient(name = "Clusters",low = "blue", high ="green")

qmplot(longitude, latitude,data = coord, maptype = "stamen_toner_lite",color=clusters_gmm,) +
    labs(title = paste("Clusters with GMM (6 clusters)")) + scale_color_gradient(name = "Clusters",low = "blue", high ="green")

qmplot(longitude, latitude,data = coord, maptype = "stamen_toner_lite",color=clusters_gmm4,) +
    labs(title = paste("Clusters with GMM (4 clusters)")) + scale_color_gradient(name = "Clusters",low = "blue", high ="green")

```



```{r}
ggplot(as.data.frame(data_pca), aes(x = pca$ind$coord[,1], y = pca$ind$coord[,2], color = as.factor(clusters_gmm4))) +
  geom_point() +
  scale_color_discrete(name = "Cluster") +
  labs(x = paste("Composante principale 1",substr(pca$eig[1],1,5),"%"), y = paste("Composante principale 2", substr(pca$eig[2],1,5),"%")) +
  theme_minimal()


ggplot(as.data.frame(data_pca), aes(x = pca$ind$coord[,1], y = pca$ind$coord[,2], color = as.factor(clusters_gmm4_spherical))) +
 geom_point() +
  scale_color_discrete(name = "Cluster") +
  labs(x = paste("Composante principale 1",substr(pca$eig[1],1,5),"%"), y = paste("Composante principale 2", substr(pca$eig[2],1,5),"%")) +
  theme_minimal()



ggplot(as.data.frame(data_pca), aes(x = pca$ind$coord[,1], y = pca$ind$coord[,2], color = as.factor(clusters_cah))) +
  geom_point() +
  scale_color_discrete(name = "Cluster") +
  labs(x = paste("Composante principale 1",substr(pca$eig[1],1,5),"%"), y = paste("Composante principale 2", substr(pca$eig[2],1,5),"%")) +
  theme_minimal()

ggplot(as.data.frame(data_pca), aes(x = pca$ind$coord[,1], y = pca$ind$coord[,2], color = as.factor(clusters_k3))) +
  geom_point() +
  scale_color_discrete(name = "Cluster") +
  labs(x = paste("Composante principale 1",substr(pca$eig[1],1,5),"%"), y = paste("Composante principale 2", substr(pca$eig[2],1,5),"%")) +
  theme_minimal()



```


## MCA 

```{r}
library(ade4)

load_quali$bonus = as.factor(load_quali$bonus)
acm = dudi.acm(load_quali, scannf = FALSE, nf = 5)

fviz_screeplot(acm<)
```

```{r}
s.label(acm$co, clabel = 0.5)
```

```{r}
library(RColorBrewer)
s.class(acm$li, load_quali$bonus, col = brewer.pal(4, "Set1"))
```



Les deux images montrent les résultats d'une analyse des correspondances multiples (ACM) sur les données de chargement des stations à Paris, en considérant les jours de semaine, le type de journée (repos ou travail) et un attribut supplémentaire nommé "Bonus". La première image révèle les profils de chargement pour chaque type de journée, indiquant des variations significatives selon les jours et si c'est un jour de travail ou de repos. La deuxième image illustre les relations entre les modalités "coline" et "plaine" du bonus et leur proximité ou éloignement vis-à-vis des profils de chargement journalier, avec une concentration notable de caractéristiques de chargement sous "coline", suggérant une association plus forte de cette modalité avec certains types de jours. Ces visualisations fournissent une compréhension détaillée des comportements de chargement en relation avec les jours typiques et les caractéristiques géographiques.


